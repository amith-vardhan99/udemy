{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "od.download(dataset_id_or_url=\"https://www.kaggle.com/datasets/aslanahmedov/number-plate-detection\",data_dir=\"C:\\\\Users\\\\amith\\\\Documents\\\\Datasets\\\\9 - Automatic Number Plate Recognition using ResNet and CNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import xml.etree.ElementTree as et\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_path = \"C:\\\\Users\\\\amith\\\\Documents\\\\Datasets\\\\9 - Automatic Number Plate Recognition using ResNet and CNN\\\\number-plate-detection\\\\images\"\n",
    "\n",
    "\n",
    "xml_list = list(map(lambda x: x if \".xml\" in x else None, os.listdir(img_list_path)))\n",
    "\n",
    "while None in xml_list:\n",
    "    xml_list.remove(None)\n",
    "\n",
    "\n",
    "img_list = list(map(lambda x: x[:x.index(\".\")] + \".jpeg\",xml_list))\n",
    "img_num = list(map(lambda x: int(x[x.index(\"N\")+1:x.index(\".\")]),xml_list))\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Image List\",\"XML List\",\"Image Number\"])\n",
    "df[\"Image List\"] = img_list\n",
    "df[\"XML List\"] = xml_list\n",
    "df[\"Image Number\"] = img_num\n",
    "\n",
    "df = df.sort_values(by=\"Image Number\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image List</th>\n",
       "      <th>XML List</th>\n",
       "      <th>Image Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N1.jpeg</td>\n",
       "      <td>N1.xml</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N2.jpeg</td>\n",
       "      <td>N2.xml</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N3.jpeg</td>\n",
       "      <td>N3.xml</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N4.jpeg</td>\n",
       "      <td>N4.xml</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N5.jpeg</td>\n",
       "      <td>N5.xml</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image List XML List  Image Number\n",
       "0    N1.jpeg   N1.xml             1\n",
       "1    N2.jpeg   N2.xml             2\n",
       "2    N3.jpeg   N3.xml             3\n",
       "3    N4.jpeg   N4.xml             4\n",
       "4    N5.jpeg   N5.xml             5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=[\"x_min\",\"y_min\",\"x_max\",\"y_max\"])\n",
    "\n",
    "img = []\n",
    "img_resized = []\n",
    "\n",
    "for i in range(df.shape[0]):   \n",
    "    img_full_path = img_list_path + \"\\\\\" + df.loc[i,\"Image List\"]\n",
    "    xml_full_path = img_list_path + \"\\\\\" + df.loc[i,\"XML List\"]\n",
    "\n",
    "    img_full = cv2.imread(img_full_path)\n",
    "    img_resized_1 = cv2.resize(src=img_full,dsize=(128,128)) / 255.0\n",
    "    img_rescaled = img_full / 255.0\n",
    "    img_resized.append(img_resized_1)\n",
    "\n",
    "    img.append(img_rescaled)\n",
    "\n",
    "    xml_tree = et.parse(xml_full_path)\n",
    "    xml_root = xml_tree.getroot()\n",
    "\n",
    "    size = xml_root.find(\"size\")\n",
    "\n",
    "    height = int(size.find(\"height\").text)\n",
    "    width = int(size.find(\"width\").text)\n",
    "\n",
    "    object = xml_root.find(\"object\")\n",
    "    bndbox = object.find(\"bndbox\")\n",
    "\n",
    "    x_min = int(bndbox.find(\"xmin\").text)\n",
    "    y_min = int(bndbox.find(\"ymin\").text)\n",
    "    x_max = int(bndbox.find(\"xmax\").text)\n",
    "    y_max = int(bndbox.find(\"ymax\").text)\n",
    "\n",
    "    df_1.loc[i,\"x_min\"] = x_min / width\n",
    "    df_1.loc[i,\"y_min\"] = y_min / height\n",
    "    df_1.loc[i,\"x_max\"] = x_max / width\n",
    "    df_1.loc[i,\"y_max\"] = y_max / height\n",
    "\n",
    "img_resized = np.array(img_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486, 720)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height,width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486, 720, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_full.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = img_resized.copy()\n",
    "y = np.array(df_1)\n",
    "\n",
    "pos = np.array(list(range(y.shape[0])))\n",
    "\n",
    "np.random.shuffle(pos)\n",
    "\n",
    "val_test_threshold = int(pos.shape[0] * 0.8)\n",
    "train_val_threshold = int(val_test_threshold * 0.8)\n",
    "\n",
    "train_pos = pos[:train_val_threshold]\n",
    "val_pos = pos[train_val_threshold:val_test_threshold]\n",
    "test_pos = pos[val_test_threshold:]\n",
    "\n",
    "X_train = X[train_pos].astype(np.float64)\n",
    "X_val = X[val_pos].astype(np.float64)\n",
    "X_test = X[test_pos].astype(np.float64)\n",
    "\n",
    "y_train = y[train_pos].astype(np.float64)\n",
    "y_val = y[val_pos].astype(np.float64)\n",
    "y_test = y[test_pos].astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(layers=[\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=8,kernel_size=(3,3),activation=\"relu\",input_shape=(128,128,3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Conv2D(filters=16,kernel_size=(3,3),activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(units=256,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=4,activation=\"sigmoid\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),loss=tf.keras.losses.mean_absolute_error,metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.5158 - loss: 0.1379 - val_accuracy: 0.5000 - val_loss: 0.1178\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5079 - loss: 0.1224 - val_accuracy: 0.5000 - val_loss: 0.1150\n",
      "Epoch 3/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5798 - loss: 0.1156 - val_accuracy: 0.7222 - val_loss: 0.1133\n",
      "Epoch 4/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6691 - loss: 0.1132 - val_accuracy: 0.5000 - val_loss: 0.1106\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6638 - loss: 0.1042 - val_accuracy: 0.6389 - val_loss: 0.1073\n",
      "Epoch 6/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6773 - loss: 0.1100 - val_accuracy: 0.6389 - val_loss: 0.1000\n",
      "Epoch 7/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7017 - loss: 0.0959 - val_accuracy: 0.7778 - val_loss: 0.1011\n",
      "Epoch 8/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7533 - loss: 0.0914 - val_accuracy: 0.8889 - val_loss: 0.0971\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6947 - loss: 0.0846 - val_accuracy: 0.8333 - val_loss: 0.0914\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8704 - loss: 0.0829 - val_accuracy: 0.8056 - val_loss: 0.0909\n",
      "Epoch 11/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8366 - loss: 0.0760 - val_accuracy: 0.8611 - val_loss: 0.0893\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8408 - loss: 0.0796 - val_accuracy: 0.8889 - val_loss: 0.0819\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8886 - loss: 0.0684 - val_accuracy: 0.7778 - val_loss: 0.0868\n",
      "Epoch 14/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9129 - loss: 0.0726 - val_accuracy: 0.8056 - val_loss: 0.0901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2bf9ccf8890>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,batch_size=10,epochs=100,verbose=1,callbacks=tf.keras.callbacks.EarlyStopping(patience=2),validation_data=(X_val,y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7389 - loss: 0.0747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07572047412395477, 0.7333333492279053]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_test,y=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.3030235 , 0.36404812, 0.7125954 , 0.61149716], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3030235 , 0.36404812, 0.7125954 , 0.61149716], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]\n",
    "\n",
    "#    df_1.loc[i,\"x_min\"] = x_min / width\n",
    "#    df_1.loc[i,\"y_min\"] = y_min / height\n",
    "#    df_1.loc[i,\"x_max\"] = x_max / width\n",
    "#    df_1.loc[i,\"y_max\"] = y_max / height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10126615910504846"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model=model,filepath=\"C:\\\\Users\\\\amith\\\\Documents\\\\GitHub\\\\udemy\\\\9 - Automatic Number Plate Recognition using ResNet and CNN\\\\app\\\\NPD.h5\")\n",
    "\n",
    "\n",
    "tf.keras.models.save_model(model=model,filepath=\"C:\\\\Users\\\\amith\\\\Documents\\\\GitHub\\\\udemy\\\\9 - Automatic Number Plate Recognition using ResNet and CNN\\\\ML_model\\\\NPD.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
