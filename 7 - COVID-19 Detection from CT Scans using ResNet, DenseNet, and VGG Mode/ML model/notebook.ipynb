{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:19:57.859132Z",
     "start_time": "2024-03-18T22:19:51.090137Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tqdm import *\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training of COVID-19 images: 100%|██████████| 4795/4795 [00:41<00:00, 115.97it/s]\n",
      "Training of Non-COVID-19 images: 100%|██████████| 604/604 [00:04<00:00, 122.90it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "covid_19 = \"C:\\\\Users\\\\amith\\\\Documents\\\\Datasets\\\\7 - COVID-19 Detection from CT Scans using ResNet, DenseNet, and VGG Mode\\\\train\\\\COVID-19\\\\\"\n",
    "non_covid_19 = \"C:\\\\Users\\\\amith\\\\Documents\\\\Datasets\\\\7 - COVID-19 Detection from CT Scans using ResNet, DenseNet, and VGG Mode\\\\train\\\\Non-COVID-19\\\\\"\n",
    "\n",
    "for i in tqdm(os.listdir(covid_19),desc=\"Training of COVID-19 images\"):\n",
    "    file_name = covid_19 + i\n",
    "    img = cv2.imread(file_name)\n",
    "    img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_resized = cv2.resize(src=img_grey,dsize=(64,64))\n",
    "    img_reshaped = img_resized / 255.0\n",
    "    img_reshaped = img_reshaped.reshape((64,64,1))\n",
    "    train_images.append(img_reshaped)\n",
    "    train_labels.append(1)\n",
    "\n",
    "for i in tqdm(os.listdir(non_covid_19),desc=\"Training of Non-COVID-19 images\"):\n",
    "    file_name = non_covid_19 + i\n",
    "    img = cv2.imread(file_name)\n",
    "    img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_resized = cv2.resize(src=img_grey,dsize=(64,64))\n",
    "    img_reshaped = img_resized / 255.0\n",
    "    img_reshaped = img_reshaped.reshape((64,64,1))\n",
    "    train_images.append(img_reshaped)\n",
    "    train_labels.append(0)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:13:53.498716Z",
     "start_time": "2024-03-18T22:13:06.717418Z"
    }
   },
   "id": "a62d02f751b17e7e",
   "execution_count": 164
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation of COVID-19 images: 100%|██████████| 1200/1200 [00:09<00:00, 126.72it/s]\n",
      "Validation of Non-COVID-19 images: 100%|██████████| 150/150 [00:01<00:00, 133.10it/s]\n"
     ]
    }
   ],
   "source": [
    "val_images = []\n",
    "val_labels = []\n",
    "\n",
    "covid_19 = \"C:\\\\Users\\\\amith\\\\Documents\\\\Datasets\\\\7 - COVID-19 Detection from CT Scans using ResNet, DenseNet, and VGG Mode\\\\val\\\\COVID-19\\\\\"\n",
    "non_covid_19 = \"C:\\\\Users\\\\amith\\\\Documents\\\\Datasets\\\\7 - COVID-19 Detection from CT Scans using ResNet, DenseNet, and VGG Mode\\\\val\\\\Non-COVID-19\\\\\"\n",
    "\n",
    "for i in tqdm(os.listdir(covid_19),desc=\"Validation of COVID-19 images\"):\n",
    "    file_name = covid_19 + i\n",
    "    img = cv2.imread(file_name)\n",
    "    img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_resized = cv2.resize(src=img_grey,dsize=(64,64))\n",
    "    img_reshaped = img_resized / 255.0\n",
    "    img_reshaped = img_reshaped.reshape((64,64,1))\n",
    "    val_images.append(img_reshaped)\n",
    "    val_labels.append(1)\n",
    "\n",
    "for i in tqdm(os.listdir(non_covid_19),desc=\"Validation of Non-COVID-19 images\"):\n",
    "    file_name = non_covid_19 + i\n",
    "    img = cv2.imread(file_name)\n",
    "    img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_resized = cv2.resize(src=img_grey,dsize=(64,64))\n",
    "    img_reshaped = img_resized / 255.0\n",
    "    img_reshaped = img_reshaped.reshape((64,64,1))\n",
    "    val_images.append(img_reshaped)\n",
    "    val_labels.append(0)\n",
    "\n",
    "val_images = np.array(val_images)\n",
    "val_labels = np.array(val_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:14:08.250587Z",
     "start_time": "2024-03-18T22:13:57.561503Z"
    }
   },
   "id": "cfc37dfe621a3b40",
   "execution_count": 165
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing of COVID-19 images: 100%|██████████| 1500/1500 [00:09<00:00, 155.72it/s]\n",
      "Testing of Non-COVID-19 images: 100%|██████████| 190/190 [00:01<00:00, 134.63it/s]\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "covid_19 = \"C:\\\\Users\\\\amith\\\\Documents\\\\Datasets\\\\7 - COVID-19 Detection from CT Scans using ResNet, DenseNet, and VGG Mode\\\\test\\\\COVID-19\\\\\"\n",
    "non_covid_19 = \"C:\\\\Users\\\\amith\\\\Documents\\\\Datasets\\\\7 - COVID-19 Detection from CT Scans using ResNet, DenseNet, and VGG Mode\\\\test\\\\Non-COVID-19\\\\\"\n",
    "\n",
    "for i in tqdm(os.listdir(covid_19),desc=\"Testing of COVID-19 images\"):\n",
    "    file_name = covid_19 + i\n",
    "    img = cv2.imread(file_name)\n",
    "    img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_resized = cv2.resize(src=img_grey,dsize=(64,64))\n",
    "    img_reshaped = img_resized / 255.0\n",
    "    img_reshaped = img_reshaped.reshape((64,64,1))\n",
    "    test_images.append(img_reshaped)\n",
    "    test_labels.append(1)\n",
    "\n",
    "for i in tqdm(os.listdir(non_covid_19),desc=\"Testing of Non-COVID-19 images\"):\n",
    "    file_name = non_covid_19 + i\n",
    "    img = cv2.imread(file_name)\n",
    "    img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_resized = cv2.resize(src=img_grey,dsize=(64,64))\n",
    "    img_reshaped = img_resized / 255.0\n",
    "    img_reshaped = img_reshaped.reshape((64,64,1))\n",
    "    test_images.append(img_reshaped)\n",
    "    test_labels.append(0)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:14:33.919848Z",
     "start_time": "2024-03-18T22:14:22.786519Z"
    }
   },
   "id": "119d875fe482ba07",
   "execution_count": 166
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(layers=[\n",
    "    tf.keras.layers.Conv2D(filters=4,kernel_size=(3,3),activation=\"relu\",input_shape=(64,64,1)),\n",
    "    tf.keras.layers.Conv2D(filters=8,kernel_size=(3,3),activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(filters=16,kernel_size=(3,3),activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(units=32,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=1,activation=\"softmax\")\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:16:04.351430Z",
     "start_time": "2024-03-18T22:16:03.441961Z"
    }
   },
   "id": "ec700b6470c26e7d",
   "execution_count": 167
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),loss=tf.keras.losses.binary_crossentropy,metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:16:55.033639Z",
     "start_time": "2024-03-18T22:16:54.997874Z"
    }
   },
   "id": "29cffac46a928b69",
   "execution_count": 168
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\amith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\amith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "169/169 [==============================] - 12s 52ms/step - loss: 0.2524 - accuracy: 0.8881 - val_loss: 0.2143 - val_accuracy: 0.8889\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 8s 47ms/step - loss: 0.1082 - accuracy: 0.8881 - val_loss: 0.2015 - val_accuracy: 0.8889\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 8s 45ms/step - loss: 0.0762 - accuracy: 0.8881 - val_loss: 0.1657 - val_accuracy: 0.8889\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 8s 47ms/step - loss: 0.0649 - accuracy: 0.8881 - val_loss: 0.1738 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x1e8702c8bd0>"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_images,y=train_labels,batch_size=32,epochs=10,verbose=1,callbacks=tf.keras.callbacks.EarlyStopping(patience=1),validation_data=(val_images,val_labels),shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:18:41.479230Z",
     "start_time": "2024-03-18T22:18:04.739053Z"
    }
   },
   "id": "88f7b4bb1998014a",
   "execution_count": 169
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 2s 27ms/step - loss: 0.3664 - accuracy: 0.8876\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.36637449264526367, 0.8875739574432373]"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=test_images,y=test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:22:51.319725Z",
     "start_time": "2024-03-18T22:22:49.613850Z"
    }
   },
   "id": "ecae60f2588fea8c",
   "execution_count": 176
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1.],\n       [1.],\n       [1.],\n       ...,\n       [1.],\n       [1.],\n       [1.]], dtype=float32)"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = model.predict(x=test_images)\n",
    "pred_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:22:53.668059Z",
     "start_time": "2024-03-18T22:22:52.204142Z"
    }
   },
   "id": "b3185a3854102746",
   "execution_count": 177
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "94.04"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = np.round(f1_score(y_true=test_labels,y_pred=pred_labels) * 100,2)\n",
    "acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:24:22.484273Z",
     "start_time": "2024-03-18T22:24:22.466075Z"
    }
   },
   "id": "c46e519fe0edc9b0",
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_91568\\1601814802.py:1: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model=model,filepath=\"C:\\\\Users\\\\amith\\\\Documents\\\\GitHub\\\\udemy\\\\7 - COVID-19 Detection from CT Scans using ResNet, DenseNet, and VGG Mode\\\\app\\\\model.h5\")\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model=model,filepath=\"C:\\\\Users\\\\amith\\\\Documents\\\\GitHub\\\\udemy\\\\7 - COVID-19 Detection from CT Scans using ResNet, DenseNet, and VGG Mode\\\\app\\\\model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:27:31.106534Z",
     "start_time": "2024-03-18T22:27:30.986627Z"
    }
   },
   "id": "8bf793c14727b664",
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "939a6e9bcceca3df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
