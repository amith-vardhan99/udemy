{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:20:04.766917Z",
     "start_time": "2023-06-24T23:20:03.774921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (8.1.3)\r\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (1.2.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (2023.5.5)\r\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (4.65.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "string = \"This is a paragraph. It should split at the end of sentence marker, such as a period. It can tell that the period in Mr. Daniel is not an end. Run it!, Hey How are you doing\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:21:56.626966Z",
     "start_time": "2023-06-24T23:21:56.625109Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['This is a paragraph',\n 'It should split at the end of sentence marker, such as a period',\n 'It can tell that the period in Mr',\n 'Daniel is not an end',\n 'Run it!, Hey How are you doing']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.split(\". \")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:21:57.684138Z",
     "start_time": "2023-06-24T23:21:57.681388Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:22:29.095531Z",
     "start_time": "2023-06-24T23:22:27.725895Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:23:18.274778Z",
     "start_time": "2023-06-24T23:23:18.270708Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\") # Tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:23:34.598718Z",
     "start_time": "2023-06-24T23:23:33.502559Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/amithsurasani/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"all\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:26:21.908810Z",
     "start_time": "2023-06-24T23:25:06.163757Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:23:43.305681Z",
     "start_time": "2023-06-24T23:23:43.301899Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sentence Tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "['This is a paragraph.',\n 'It should split at the end of sentence marker, such as a period.',\n 'It can tell that the period in Mr. Daniel is not an end.',\n 'Run it!, Hey How are you doing']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:23:56.770739Z",
     "start_time": "2023-06-24T23:23:56.762932Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:26:38.940916Z",
     "start_time": "2023-06-24T23:26:38.937317Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Word Tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "['This',\n 'is',\n 'a',\n 'paragraph',\n '.',\n 'It',\n 'should',\n 'split',\n 'at',\n 'the',\n 'end',\n 'of',\n 'sentence',\n 'marker',\n ',',\n 'such',\n 'as',\n 'a',\n 'period',\n '.',\n 'It',\n 'can',\n 'tell',\n 'that',\n 'the',\n 'period',\n 'in',\n 'Mr.',\n 'Daniel',\n 'is',\n 'not',\n 'an',\n 'end',\n '.',\n 'Run',\n 'it',\n '!',\n ',',\n 'Hey',\n 'How',\n 'are',\n 'you',\n 'doing']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:29:45.708417Z",
     "start_time": "2023-06-24T23:29:45.706315Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regular Expression Tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize, regexp_tokenize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:32:21.506683Z",
     "start_time": "2023-06-24T23:32:21.504235Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "['This',\n 'is',\n 'a',\n 'paragraph',\n 'It',\n 'should',\n 'split',\n 'at',\n 'the',\n 'end',\n 'of',\n 'sentence',\n 'marker',\n 'such',\n 'as',\n 'a',\n 'period',\n 'It',\n 'can',\n 'tell',\n 'that',\n 'the',\n 'period',\n 'in',\n 'Mr',\n 'Daniel',\n 'is',\n 'not',\n 'an',\n 'end',\n 'Run',\n 'it',\n 'Hey',\n 'How',\n 'are',\n 'you',\n 'doing']"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tokenize(string,pattern=\"\\w+\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:32:54.544110Z",
     "start_time": "2023-06-24T23:32:54.540726Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stemming"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:50:36.308022Z",
     "start_time": "2023-06-24T23:50:36.303425Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "'cut'"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "porter.stem(\"cutting\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:50:51.660498Z",
     "start_time": "2023-06-24T23:50:51.657835Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "'cri'"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"crying\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:51:13.806890Z",
     "start_time": "2023-06-24T23:51:13.804840Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "'aww'"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"aww\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:51:19.432924Z",
     "start_time": "2023-06-24T23:51:19.428601Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "'ew'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"ew\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:51:38.417323Z",
     "start_time": "2023-06-24T23:51:38.415431Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "'condit'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"condition\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:52:43.814510Z",
     "start_time": "2023-06-24T23:52:43.809610Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lemmatization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:53:50.362033Z",
     "start_time": "2023-06-24T23:53:50.358663Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "wl=WordNetLemmatizer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:56:37.649767Z",
     "start_time": "2023-06-24T23:56:37.645625Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "'corpus'"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize(\"corpora\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:56:38.410614Z",
     "start_time": "2023-06-24T23:56:38.404813Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "'cry'"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize(\"crying\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:56:38.671914Z",
     "start_time": "2023-06-24T23:56:38.666279Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "'This is a paragraph. It should split at the end of sentence marker, such as a period. It can tell that the period in Mr. Daniel is not an end. Run it!, Hey How are you doing'"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:56:39.017676Z",
     "start_time": "2023-06-24T23:56:39.012478Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "['This',\n 'is',\n 'a',\n 'paragraph',\n 'It',\n 'should',\n 'split',\n 'at',\n 'the',\n 'end',\n 'of',\n 'sentence',\n 'marker',\n 'such',\n 'as',\n 'a',\n 'period',\n 'It',\n 'can',\n 'tell',\n 'that',\n 'the',\n 'period',\n 'in',\n 'Mr',\n 'Daniel',\n 'is',\n 'not',\n 'an',\n 'end',\n 'Run',\n 'it',\n 'Hey',\n 'How',\n 'are',\n 'you',\n 'doing']"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = regexp_tokenize(string,pattern=\"\\w+\")\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:57:17.617305Z",
     "start_time": "2023-06-24T23:57:17.613403Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stemmed version of This is thi \n",
      "The lemmatized version of This is This \n",
      "\n",
      "The stemmed version of is is is \n",
      "The lemmatized version of is is is \n",
      "\n",
      "The stemmed version of a is a \n",
      "The lemmatized version of a is a \n",
      "\n",
      "The stemmed version of paragraph is paragraph \n",
      "The lemmatized version of paragraph is paragraph \n",
      "\n",
      "The stemmed version of It is it \n",
      "The lemmatized version of It is It \n",
      "\n",
      "The stemmed version of should is should \n",
      "The lemmatized version of should is should \n",
      "\n",
      "The stemmed version of split is split \n",
      "The lemmatized version of split is split \n",
      "\n",
      "The stemmed version of at is at \n",
      "The lemmatized version of at is at \n",
      "\n",
      "The stemmed version of the is the \n",
      "The lemmatized version of the is the \n",
      "\n",
      "The stemmed version of end is end \n",
      "The lemmatized version of end is end \n",
      "\n",
      "The stemmed version of of is of \n",
      "The lemmatized version of of is of \n",
      "\n",
      "The stemmed version of sentence is sentenc \n",
      "The lemmatized version of sentence is sentence \n",
      "\n",
      "The stemmed version of marker is marker \n",
      "The lemmatized version of marker is marker \n",
      "\n",
      "The stemmed version of such is such \n",
      "The lemmatized version of such is such \n",
      "\n",
      "The stemmed version of as is as \n",
      "The lemmatized version of as is a \n",
      "\n",
      "The stemmed version of a is a \n",
      "The lemmatized version of a is a \n",
      "\n",
      "The stemmed version of period is period \n",
      "The lemmatized version of period is period \n",
      "\n",
      "The stemmed version of It is it \n",
      "The lemmatized version of It is It \n",
      "\n",
      "The stemmed version of can is can \n",
      "The lemmatized version of can is can \n",
      "\n",
      "The stemmed version of tell is tell \n",
      "The lemmatized version of tell is tell \n",
      "\n",
      "The stemmed version of that is that \n",
      "The lemmatized version of that is that \n",
      "\n",
      "The stemmed version of the is the \n",
      "The lemmatized version of the is the \n",
      "\n",
      "The stemmed version of period is period \n",
      "The lemmatized version of period is period \n",
      "\n",
      "The stemmed version of in is in \n",
      "The lemmatized version of in is in \n",
      "\n",
      "The stemmed version of Mr is mr \n",
      "The lemmatized version of Mr is Mr \n",
      "\n",
      "The stemmed version of Daniel is daniel \n",
      "The lemmatized version of Daniel is Daniel \n",
      "\n",
      "The stemmed version of is is is \n",
      "The lemmatized version of is is is \n",
      "\n",
      "The stemmed version of not is not \n",
      "The lemmatized version of not is not \n",
      "\n",
      "The stemmed version of an is an \n",
      "The lemmatized version of an is an \n",
      "\n",
      "The stemmed version of end is end \n",
      "The lemmatized version of end is end \n",
      "\n",
      "The stemmed version of Run is run \n",
      "The lemmatized version of Run is Run \n",
      "\n",
      "The stemmed version of it is it \n",
      "The lemmatized version of it is it \n",
      "\n",
      "The stemmed version of Hey is hey \n",
      "The lemmatized version of Hey is Hey \n",
      "\n",
      "The stemmed version of How is how \n",
      "The lemmatized version of How is How \n",
      "\n",
      "The stemmed version of are is are \n",
      "The lemmatized version of are is are \n",
      "\n",
      "The stemmed version of you is you \n",
      "The lemmatized version of you is you \n",
      "\n",
      "The stemmed version of doing is do \n",
      "The lemmatized version of doing is doing \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "    print(\"The stemmed version of {} is {} \".format(i,porter.stem(i)))\n",
    "    print(\"The lemmatized version of {} is {} \".format(i,wl.lemmatize(i)))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T23:59:42.508500Z",
     "start_time": "2023-06-24T23:59:42.505140Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stop word removal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:01:16.385296Z",
     "start_time": "2023-06-25T00:01:16.381617Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "['i',\n 'me',\n 'my',\n 'myself',\n 'we',\n 'our',\n 'ours',\n 'ourselves',\n 'you',\n \"you're\",\n \"you've\",\n \"you'll\",\n \"you'd\",\n 'your',\n 'yours',\n 'yourself',\n 'yourselves',\n 'he',\n 'him',\n 'his',\n 'himself',\n 'she',\n \"she's\",\n 'her',\n 'hers',\n 'herself',\n 'it',\n \"it's\",\n 'its',\n 'itself',\n 'they',\n 'them',\n 'their',\n 'theirs',\n 'themselves',\n 'what',\n 'which',\n 'who',\n 'whom',\n 'this',\n 'that',\n \"that'll\",\n 'these',\n 'those',\n 'am',\n 'is',\n 'are',\n 'was',\n 'were',\n 'be',\n 'been',\n 'being',\n 'have',\n 'has',\n 'had',\n 'having',\n 'do',\n 'does',\n 'did',\n 'doing',\n 'a',\n 'an',\n 'the',\n 'and',\n 'but',\n 'if',\n 'or',\n 'because',\n 'as',\n 'until',\n 'while',\n 'of',\n 'at',\n 'by',\n 'for',\n 'with',\n 'about',\n 'against',\n 'between',\n 'into',\n 'through',\n 'during',\n 'before',\n 'after',\n 'above',\n 'below',\n 'to',\n 'from',\n 'up',\n 'down',\n 'in',\n 'out',\n 'on',\n 'off',\n 'over',\n 'under',\n 'again',\n 'further',\n 'then',\n 'once',\n 'here',\n 'there',\n 'when',\n 'where',\n 'why',\n 'how',\n 'all',\n 'any',\n 'both',\n 'each',\n 'few',\n 'more',\n 'most',\n 'other',\n 'some',\n 'such',\n 'no',\n 'nor',\n 'not',\n 'only',\n 'own',\n 'same',\n 'so',\n 'than',\n 'too',\n 'very',\n 's',\n 't',\n 'can',\n 'will',\n 'just',\n 'don',\n \"don't\",\n 'should',\n \"should've\",\n 'now',\n 'd',\n 'll',\n 'm',\n 'o',\n 're',\n 've',\n 'y',\n 'ain',\n 'aren',\n \"aren't\",\n 'couldn',\n \"couldn't\",\n 'didn',\n \"didn't\",\n 'doesn',\n \"doesn't\",\n 'hadn',\n \"hadn't\",\n 'hasn',\n \"hasn't\",\n 'haven',\n \"haven't\",\n 'isn',\n \"isn't\",\n 'ma',\n 'mightn',\n \"mightn't\",\n 'mustn',\n \"mustn't\",\n 'needn',\n \"needn't\",\n 'shan',\n \"shan't\",\n 'shouldn',\n \"shouldn't\",\n 'wasn',\n \"wasn't\",\n 'weren',\n \"weren't\",\n 'won',\n \"won't\",\n 'wouldn',\n \"wouldn't\"]"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:01:31.584996Z",
     "start_time": "2023-06-25T00:01:31.581325Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "['и',\n 'в',\n 'во',\n 'не',\n 'что',\n 'он',\n 'на',\n 'я',\n 'с',\n 'со',\n 'как',\n 'а',\n 'то',\n 'все',\n 'она',\n 'так',\n 'его',\n 'но',\n 'да',\n 'ты',\n 'к',\n 'у',\n 'же',\n 'вы',\n 'за',\n 'бы',\n 'по',\n 'только',\n 'ее',\n 'мне',\n 'было',\n 'вот',\n 'от',\n 'меня',\n 'еще',\n 'нет',\n 'о',\n 'из',\n 'ему',\n 'теперь',\n 'когда',\n 'даже',\n 'ну',\n 'вдруг',\n 'ли',\n 'если',\n 'уже',\n 'или',\n 'ни',\n 'быть',\n 'был',\n 'него',\n 'до',\n 'вас',\n 'нибудь',\n 'опять',\n 'уж',\n 'вам',\n 'ведь',\n 'там',\n 'потом',\n 'себя',\n 'ничего',\n 'ей',\n 'может',\n 'они',\n 'тут',\n 'где',\n 'есть',\n 'надо',\n 'ней',\n 'для',\n 'мы',\n 'тебя',\n 'их',\n 'чем',\n 'была',\n 'сам',\n 'чтоб',\n 'без',\n 'будто',\n 'чего',\n 'раз',\n 'тоже',\n 'себе',\n 'под',\n 'будет',\n 'ж',\n 'тогда',\n 'кто',\n 'этот',\n 'того',\n 'потому',\n 'этого',\n 'какой',\n 'совсем',\n 'ним',\n 'здесь',\n 'этом',\n 'один',\n 'почти',\n 'мой',\n 'тем',\n 'чтобы',\n 'нее',\n 'сейчас',\n 'были',\n 'куда',\n 'зачем',\n 'всех',\n 'никогда',\n 'можно',\n 'при',\n 'наконец',\n 'два',\n 'об',\n 'другой',\n 'хоть',\n 'после',\n 'над',\n 'больше',\n 'тот',\n 'через',\n 'эти',\n 'нас',\n 'про',\n 'всего',\n 'них',\n 'какая',\n 'много',\n 'разве',\n 'три',\n 'эту',\n 'моя',\n 'впрочем',\n 'хорошо',\n 'свою',\n 'этой',\n 'перед',\n 'иногда',\n 'лучше',\n 'чуть',\n 'том',\n 'нельзя',\n 'такой',\n 'им',\n 'более',\n 'всегда',\n 'конечно',\n 'всю',\n 'между']"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"russian\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:02:32.166380Z",
     "start_time": "2023-06-25T00:02:32.162842Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "['arabic',\n 'azerbaijani',\n 'basque',\n 'bengali',\n 'catalan',\n 'chinese',\n 'danish',\n 'dutch',\n 'english',\n 'finnish',\n 'french',\n 'german',\n 'greek',\n 'hebrew',\n 'hinglish',\n 'hungarian',\n 'indonesian',\n 'italian',\n 'kazakh',\n 'nepali',\n 'norwegian',\n 'portuguese',\n 'romanian',\n 'russian',\n 'slovene',\n 'spanish',\n 'swedish',\n 'tajik',\n 'turkish']"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:03:56.053161Z",
     "start_time": "2023-06-25T00:03:56.043330Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "['a',\n 'aadi',\n 'aaj',\n 'aap',\n 'aapne',\n 'aata',\n 'aati',\n 'aaya',\n 'aaye',\n 'ab',\n 'abbe',\n 'abbey',\n 'abe',\n 'abhi',\n 'able',\n 'about',\n 'above',\n 'accha',\n 'according',\n 'accordingly',\n 'acha',\n 'achcha',\n 'across',\n 'actually',\n 'after',\n 'afterwards',\n 'again',\n 'against',\n 'agar',\n 'ain',\n 'aint',\n \"ain't\",\n 'aisa',\n 'aise',\n 'aisi',\n 'alag',\n 'all',\n 'allow',\n 'allows',\n 'almost',\n 'alone',\n 'along',\n 'already',\n 'also',\n 'although',\n 'always',\n 'am',\n 'among',\n 'amongst',\n 'an',\n 'and',\n 'andar',\n 'another',\n 'any',\n 'anybody',\n 'anyhow',\n 'anyone',\n 'anything',\n 'anyway',\n 'anyways',\n 'anywhere',\n 'ap',\n 'apan',\n 'apart',\n 'apna',\n 'apnaa',\n 'apne',\n 'apni',\n 'appear',\n 'are',\n 'aren',\n 'arent',\n \"aren't\",\n 'around',\n 'arre',\n 'as',\n 'aside',\n 'ask',\n 'asking',\n 'at',\n 'aur',\n 'avum',\n 'aya',\n 'aye',\n 'baad',\n 'baar',\n 'bad',\n 'bahut',\n 'bana',\n 'banae',\n 'banai',\n 'banao',\n 'banaya',\n 'banaye',\n 'banayi',\n 'banda',\n 'bande',\n 'bandi',\n 'bane',\n 'bani',\n 'bas',\n 'bata',\n 'batao',\n 'bc',\n 'be',\n 'became',\n 'because',\n 'become',\n 'becomes',\n 'becoming',\n 'been',\n 'before',\n 'beforehand',\n 'behind',\n 'being',\n 'below',\n 'beside',\n 'besides',\n 'best',\n 'better',\n 'between',\n 'beyond',\n 'bhai',\n 'bheetar',\n 'bhi',\n 'bhitar',\n 'bht',\n 'bilkul',\n 'bohot',\n 'bol',\n 'bola',\n 'bole',\n 'boli',\n 'bolo',\n 'bolta',\n 'bolte',\n 'bolti',\n 'both',\n 'brief',\n 'bro',\n 'btw',\n 'but',\n 'by',\n 'came',\n 'can',\n 'cannot',\n 'cant',\n \"can't\",\n 'cause',\n 'causes',\n 'certain',\n 'certainly',\n 'chahiye',\n 'chaiye',\n 'chal',\n 'chalega',\n 'chhaiye',\n 'clearly',\n \"c'mon\",\n 'com',\n 'come',\n 'comes',\n 'could',\n 'couldn',\n 'couldnt',\n \"couldn't\",\n 'd',\n 'de',\n 'dede',\n 'dega',\n 'degi',\n 'dekh',\n 'dekha',\n 'dekhe',\n 'dekhi',\n 'dekho',\n 'denge',\n 'dhang',\n 'di',\n 'did',\n 'didn',\n 'didnt',\n \"didn't\",\n 'dijiye',\n 'diya',\n 'diyaa',\n 'diye',\n 'diyo',\n 'do',\n 'does',\n 'doesn',\n 'doesnt',\n \"doesn't\",\n 'doing',\n 'done',\n 'dono',\n 'dont',\n \"don't\",\n 'doosra',\n 'doosre',\n 'down',\n 'downwards',\n 'dude',\n 'dunga',\n 'dungi',\n 'during',\n 'dusra',\n 'dusre',\n 'dusri',\n 'dvaara',\n 'dvara',\n 'dwaara',\n 'dwara',\n 'each',\n 'edu',\n 'eg',\n 'eight',\n 'either',\n 'ek',\n 'else',\n 'elsewhere',\n 'enough',\n 'etc',\n 'even',\n 'ever',\n 'every',\n 'everybody',\n 'everyone',\n 'everything',\n 'everywhere',\n 'ex',\n 'exactly',\n 'example',\n 'except',\n 'far',\n 'few',\n 'fifth',\n 'fir',\n 'first',\n 'five',\n 'followed',\n 'following',\n 'follows',\n 'for',\n 'forth',\n 'four',\n 'from',\n 'further',\n 'furthermore',\n 'gaya',\n 'gaye',\n 'gayi',\n 'get',\n 'gets',\n 'getting',\n 'ghar',\n 'given',\n 'gives',\n 'go',\n 'goes',\n 'going',\n 'gone',\n 'good',\n 'got',\n 'gotten',\n 'greetings',\n 'haan',\n 'had',\n 'hadd',\n 'hadn',\n 'hadnt',\n \"hadn't\",\n 'hai',\n 'hain',\n 'hamara',\n 'hamare',\n 'hamari',\n 'hamne',\n 'han',\n 'happens',\n 'har',\n 'hardly',\n 'has',\n 'hasn',\n 'hasnt',\n \"hasn't\",\n 'have',\n 'haven',\n 'havent',\n \"haven't\",\n 'having',\n 'he',\n 'hello',\n 'help',\n 'hence',\n 'her',\n 'here',\n 'hereafter',\n 'hereby',\n 'herein',\n \"here's\",\n 'hereupon',\n 'hers',\n 'herself',\n \"he's\",\n 'hi',\n 'him',\n 'himself',\n 'his',\n 'hither',\n 'hm',\n 'hmm',\n 'ho',\n 'hoga',\n 'hoge',\n 'hogi',\n 'hona',\n 'honaa',\n 'hone',\n 'honge',\n 'hongi',\n 'honi',\n 'hopefully',\n 'hota',\n 'hotaa',\n 'hote',\n 'hoti',\n 'how',\n 'howbeit',\n 'however',\n 'hoyenge',\n 'hoyengi',\n 'hu',\n 'hua',\n 'hue',\n 'huh',\n 'hui',\n 'hum',\n 'humein',\n 'humne',\n 'hun',\n 'huye',\n 'huyi',\n 'i',\n \"i'd\",\n 'idk',\n 'ie',\n 'if',\n \"i'll\",\n \"i'm\",\n 'imo',\n 'in',\n 'inasmuch',\n 'inc',\n 'inhe',\n 'inhi',\n 'inho',\n 'inka',\n 'inkaa',\n 'inke',\n 'inki',\n 'inn',\n 'inner',\n 'inse',\n 'insofar',\n 'into',\n 'inward',\n 'is',\n 'ise',\n 'isi',\n 'iska',\n 'iskaa',\n 'iske',\n 'iski',\n 'isme',\n 'isn',\n 'isne',\n 'isnt',\n \"isn't\",\n 'iss',\n 'isse',\n 'issi',\n 'isski',\n 'it',\n \"it'd\",\n \"it'll\",\n 'itna',\n 'itne',\n 'itni',\n 'itno',\n 'its',\n \"it's\",\n 'itself',\n 'ityaadi',\n 'ityadi',\n \"i've\",\n 'ja',\n 'jaa',\n 'jab',\n 'jabh',\n 'jaha',\n 'jahaan',\n 'jahan',\n 'jaisa',\n 'jaise',\n 'jaisi',\n 'jata',\n 'jayega',\n 'jidhar',\n 'jin',\n 'jinhe',\n 'jinhi',\n 'jinho',\n 'jinhone',\n 'jinka',\n 'jinke',\n 'jinki',\n 'jinn',\n 'jis',\n 'jise',\n 'jiska',\n 'jiske',\n 'jiski',\n 'jisme',\n 'jiss',\n 'jisse',\n 'jitna',\n 'jitne',\n 'jitni',\n 'jo',\n 'just',\n 'jyaada',\n 'jyada',\n 'k',\n 'ka',\n 'kaafi',\n 'kab',\n 'kabhi',\n 'kafi',\n 'kaha',\n 'kahaa',\n 'kahaan',\n 'kahan',\n 'kahi',\n 'kahin',\n 'kahte',\n 'kaisa',\n 'kaise',\n 'kaisi',\n 'kal',\n 'kam',\n 'kar',\n 'kara',\n 'kare',\n 'karega',\n 'karegi',\n 'karen',\n 'karenge',\n 'kari',\n 'karke',\n 'karna',\n 'karne',\n 'karni',\n 'karo',\n 'karta',\n 'karte',\n 'karti',\n 'karu',\n 'karun',\n 'karunga',\n 'karungi',\n 'kaun',\n 'kaunsa',\n 'kayi',\n 'kch',\n 'ke',\n 'keep',\n 'keeps',\n 'keh',\n 'kehte',\n 'kept',\n 'khud',\n 'ki',\n 'kin',\n 'kine',\n 'kinhe',\n 'kinho',\n 'kinka',\n 'kinke',\n 'kinki',\n 'kinko',\n 'kinn',\n 'kino',\n 'kis',\n 'kise',\n 'kisi',\n 'kiska',\n 'kiske',\n 'kiski',\n 'kisko',\n 'kisliye',\n 'kisne',\n 'kitna',\n 'kitne',\n 'kitni',\n 'kitno',\n 'kiya',\n 'kiye',\n 'know',\n 'known',\n 'knows',\n 'ko',\n 'koi',\n 'kon',\n 'konsa',\n 'koyi',\n 'krna',\n 'krne',\n 'kuch',\n 'kuchch',\n 'kuchh',\n 'kul',\n 'kull',\n 'kya',\n 'kyaa',\n 'kyu',\n 'kyuki',\n 'kyun',\n 'kyunki',\n 'lagta',\n 'lagte',\n 'lagti',\n 'last',\n 'lately',\n 'later',\n 'le',\n 'least',\n 'lekar',\n 'lekin',\n 'less',\n 'lest',\n 'let',\n \"let's\",\n 'li',\n 'like',\n 'liked',\n 'likely',\n 'little',\n 'liya',\n 'liye',\n 'll',\n 'lo',\n 'log',\n 'logon',\n 'lol',\n 'look',\n 'looking',\n 'looks',\n 'ltd',\n 'lunga',\n 'm',\n 'maan',\n 'maana',\n 'maane',\n 'maani',\n 'maano',\n 'magar',\n 'mai',\n 'main',\n 'maine',\n 'mainly',\n 'mana',\n 'mane',\n 'mani',\n 'mano',\n 'many',\n 'mat',\n 'may',\n 'maybe',\n 'me',\n 'mean',\n 'meanwhile',\n 'mein',\n 'mera',\n 'mere',\n 'merely',\n 'meri',\n 'might',\n 'mightn',\n 'mightnt',\n \"mightn't\",\n 'mil',\n 'mjhe',\n 'more',\n 'moreover',\n 'most',\n 'mostly',\n 'much',\n 'mujhe',\n 'must',\n 'mustn',\n 'mustnt',\n \"mustn't\",\n 'my',\n 'myself',\n 'na',\n 'naa',\n 'naah',\n 'nahi',\n 'nahin',\n 'nai',\n 'name',\n 'namely',\n 'nd',\n 'ne',\n 'near',\n 'nearly',\n 'necessary',\n 'neeche',\n 'need',\n 'needn',\n 'neednt',\n \"needn't\",\n 'needs',\n 'neither',\n 'never',\n 'nevertheless',\n 'new',\n 'next',\n 'nhi',\n 'nine',\n 'no',\n 'nobody',\n 'non',\n 'none',\n 'noone',\n 'nope',\n 'nor',\n 'normally',\n 'not',\n 'nothing',\n 'novel',\n 'now',\n 'nowhere',\n 'o',\n 'obviously',\n 'of',\n 'off',\n 'often',\n 'oh',\n 'ok',\n 'okay',\n 'old',\n 'on',\n 'once',\n 'one',\n 'ones',\n 'only',\n 'onto',\n 'or',\n 'other',\n 'others',\n 'otherwise',\n 'ought',\n 'our',\n 'ours',\n 'ourselves',\n 'out',\n 'outside',\n 'over',\n 'overall',\n 'own',\n 'par',\n 'pata',\n 'pe',\n 'pehla',\n 'pehle',\n 'pehli',\n 'people',\n 'per',\n 'perhaps',\n 'phla',\n 'phle',\n 'phli',\n 'placed',\n 'please',\n 'plus',\n 'poora',\n 'poori',\n 'provides',\n 'pura',\n 'puri',\n 'q',\n 'que',\n 'quite',\n 'raha',\n 'rahaa',\n 'rahe',\n 'rahi',\n 'rakh',\n 'rakha',\n 'rakhe',\n 'rakhen',\n 'rakhi',\n 'rakho',\n 'rather',\n 're',\n 'really',\n 'reasonably',\n 'regarding',\n 'regardless',\n 'regards',\n 'rehte',\n 'rha',\n 'rhaa',\n 'rhe',\n 'rhi',\n 'ri',\n 'right',\n 's',\n 'sa',\n 'saara',\n 'saare',\n 'saath',\n 'sab',\n 'sabhi',\n 'sabse',\n 'sahi',\n 'said',\n 'sakta',\n 'saktaa',\n 'sakte',\n 'sakti',\n 'same',\n 'sang',\n 'sara',\n 'sath',\n 'saw',\n 'say',\n 'saying',\n 'says',\n 'se',\n 'second',\n 'secondly',\n 'see',\n 'seeing',\n 'seem',\n 'seemed',\n 'seeming',\n 'seems',\n 'seen',\n 'self',\n 'selves',\n 'sensible',\n 'sent',\n 'serious',\n 'seriously',\n 'seven',\n 'several',\n 'shall',\n 'shan',\n 'shant',\n \"shan't\",\n 'she',\n \"she's\",\n 'should',\n 'shouldn',\n 'shouldnt',\n \"shouldn't\",\n \"should've\",\n 'si',\n 'since',\n 'six',\n 'so',\n 'soch',\n 'some',\n 'somebody',\n 'somehow',\n 'someone',\n 'something',\n 'sometime',\n 'sometimes',\n 'somewhat',\n 'somewhere',\n 'soon',\n 'still',\n 'sub',\n 'such',\n 'sup',\n 'sure',\n 't',\n 'tab',\n 'tabh',\n 'tak',\n 'take',\n 'taken',\n 'tarah',\n 'teen',\n 'teeno',\n 'teesra',\n 'teesre',\n 'teesri',\n 'tell',\n 'tends',\n 'tera',\n 'tere',\n 'teri',\n 'th',\n 'tha',\n 'than',\n 'thank',\n 'thanks',\n 'thanx',\n 'that',\n \"that'll\",\n 'thats',\n \"that's\",\n 'the',\n 'theek',\n 'their',\n 'theirs',\n 'them',\n 'themselves',\n 'then',\n 'thence',\n 'there',\n 'thereafter',\n 'thereby',\n 'therefore',\n 'therein',\n 'theres',\n \"there's\",\n 'thereupon',\n 'these',\n 'they',\n \"they'd\",\n \"they'll\",\n \"they're\",\n \"they've\",\n 'thi',\n 'thik',\n 'thing',\n 'think',\n 'thinking',\n 'third',\n 'this',\n 'tho',\n 'thoda',\n 'thodi',\n 'thorough',\n 'thoroughly',\n 'those',\n 'though',\n 'thought',\n 'three',\n 'through',\n 'throughout',\n 'thru',\n 'thus',\n 'tjhe',\n 'to',\n 'together',\n 'toh',\n 'too',\n 'took',\n 'toward',\n 'towards',\n 'tried',\n 'tries',\n 'true',\n 'truly',\n 'try',\n 'trying',\n 'tu',\n 'tujhe',\n 'tum',\n 'tumhara',\n 'tumhare',\n 'tumhari',\n 'tune',\n 'twice',\n 'two',\n 'um',\n 'umm',\n 'un',\n 'under',\n 'unhe',\n 'unhi',\n 'unho',\n 'unhone',\n 'unka',\n 'unkaa',\n 'unke',\n 'unki',\n 'unko',\n 'unless',\n 'unlikely',\n 'unn',\n 'unse',\n 'until',\n 'unto',\n 'up',\n 'upar',\n 'upon',\n 'us',\n 'use',\n 'used',\n 'useful',\n 'uses',\n 'usi',\n 'using',\n 'uska',\n 'uske',\n 'usne',\n 'uss',\n 'usse',\n 'ussi',\n 'usually',\n 'vaala',\n 'vaale',\n 'vaali',\n 'vahaan',\n 'vahan',\n 'vahi',\n 'vahin',\n 'vaisa',\n 'vaise',\n 'vaisi',\n 'vala',\n 'vale',\n 'vali',\n 'various',\n 've',\n 'very',\n 'via',\n 'viz',\n 'vo',\n 'waala',\n 'waale',\n 'waali',\n 'wagaira',\n 'wagairah',\n 'wagerah',\n 'waha',\n 'wahaan',\n 'wahan',\n 'wahi',\n 'wahin',\n 'waisa',\n 'waise',\n 'waisi',\n 'wala',\n 'wale',\n 'wali',\n 'want',\n 'wants',\n 'was',\n 'wasn',\n 'wasnt',\n \"wasn't\",\n 'way',\n 'we',\n \"we'd\",\n 'well',\n \"we'll\",\n 'went',\n 'were',\n \"we're\",\n 'weren',\n 'werent',\n \"weren't\",\n \"we've\",\n 'what',\n 'whatever',\n \"what's\",\n 'when',\n 'whence',\n 'whenever',\n 'where',\n 'whereafter',\n 'whereas',\n 'whereby',\n 'wherein',\n \"where's\",\n 'whereupon',\n 'wherever',\n 'whether',\n 'which',\n 'while',\n 'who',\n 'whoever',\n 'whole',\n 'whom',\n \"who's\",\n 'whose',\n 'why',\n 'will',\n 'willing',\n 'with',\n 'within',\n ...]"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"hinglish\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:04:32.784975Z",
     "start_time": "2023-06-25T00:04:32.778581Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "'This is a paragraph. It should split at the end of sentence marker, such as a period. It can tell that the period in Mr. Daniel is not an end. Run it!, Hey How are you doing'"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:06:30.319415Z",
     "start_time": "2023-06-25T00:06:30.314306Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'paragraph', 'It', 'split', 'end', 'sentence', 'marker', 'period', 'It', 'tell', 'period', 'Mr', 'Daniel', 'end', 'Run', 'Hey', 'How']\n"
     ]
    }
   ],
   "source": [
    "list = stopwords.words(\"english\")\n",
    "words =regexp_tokenize(string,pattern=\"\\w+\")\n",
    "l = []\n",
    "for i in words:\n",
    "\tif i not in list:\n",
    "\t\tl.append(i)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:08:12.753527Z",
     "start_time": "2023-06-25T00:08:12.748445Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "['إذ',\n 'إذا',\n 'إذما',\n 'إذن',\n 'أف',\n 'أقل',\n 'أكثر',\n 'ألا',\n 'إلا',\n 'التي',\n 'الذي',\n 'الذين',\n 'اللاتي',\n 'اللائي',\n 'اللتان',\n 'اللتيا',\n 'اللتين',\n 'اللذان',\n 'اللذين',\n 'اللواتي',\n 'إلى',\n 'إليك',\n 'إليكم',\n 'إليكما',\n 'إليكن',\n 'أم',\n 'أما',\n 'أما',\n 'إما',\n 'أن',\n 'إن',\n 'إنا',\n 'أنا',\n 'أنت',\n 'أنتم',\n 'أنتما',\n 'أنتن',\n 'إنما',\n 'إنه',\n 'أنى',\n 'أنى',\n 'آه',\n 'آها',\n 'أو',\n 'أولاء',\n 'أولئك',\n 'أوه',\n 'آي',\n 'أي',\n 'أيها',\n 'إي',\n 'أين',\n 'أين',\n 'أينما',\n 'إيه',\n 'بخ',\n 'بس',\n 'بعد',\n 'بعض',\n 'بك',\n 'بكم',\n 'بكم',\n 'بكما',\n 'بكن',\n 'بل',\n 'بلى',\n 'بما',\n 'بماذا',\n 'بمن',\n 'بنا',\n 'به',\n 'بها',\n 'بهم',\n 'بهما',\n 'بهن',\n 'بي',\n 'بين',\n 'بيد',\n 'تلك',\n 'تلكم',\n 'تلكما',\n 'ته',\n 'تي',\n 'تين',\n 'تينك',\n 'ثم',\n 'ثمة',\n 'حاشا',\n 'حبذا',\n 'حتى',\n 'حيث',\n 'حيثما',\n 'حين',\n 'خلا',\n 'دون',\n 'ذا',\n 'ذات',\n 'ذاك',\n 'ذان',\n 'ذانك',\n 'ذلك',\n 'ذلكم',\n 'ذلكما',\n 'ذلكن',\n 'ذه',\n 'ذو',\n 'ذوا',\n 'ذواتا',\n 'ذواتي',\n 'ذي',\n 'ذين',\n 'ذينك',\n 'ريث',\n 'سوف',\n 'سوى',\n 'شتان',\n 'عدا',\n 'عسى',\n 'عل',\n 'على',\n 'عليك',\n 'عليه',\n 'عما',\n 'عن',\n 'عند',\n 'غير',\n 'فإذا',\n 'فإن',\n 'فلا',\n 'فمن',\n 'في',\n 'فيم',\n 'فيما',\n 'فيه',\n 'فيها',\n 'قد',\n 'كأن',\n 'كأنما',\n 'كأي',\n 'كأين',\n 'كذا',\n 'كذلك',\n 'كل',\n 'كلا',\n 'كلاهما',\n 'كلتا',\n 'كلما',\n 'كليكما',\n 'كليهما',\n 'كم',\n 'كم',\n 'كما',\n 'كي',\n 'كيت',\n 'كيف',\n 'كيفما',\n 'لا',\n 'لاسيما',\n 'لدى',\n 'لست',\n 'لستم',\n 'لستما',\n 'لستن',\n 'لسن',\n 'لسنا',\n 'لعل',\n 'لك',\n 'لكم',\n 'لكما',\n 'لكن',\n 'لكنما',\n 'لكي',\n 'لكيلا',\n 'لم',\n 'لما',\n 'لن',\n 'لنا',\n 'له',\n 'لها',\n 'لهم',\n 'لهما',\n 'لهن',\n 'لو',\n 'لولا',\n 'لوما',\n 'لي',\n 'لئن',\n 'ليت',\n 'ليس',\n 'ليسا',\n 'ليست',\n 'ليستا',\n 'ليسوا',\n 'ما',\n 'ماذا',\n 'متى',\n 'مذ',\n 'مع',\n 'مما',\n 'ممن',\n 'من',\n 'منه',\n 'منها',\n 'منذ',\n 'مه',\n 'مهما',\n 'نحن',\n 'نحو',\n 'نعم',\n 'ها',\n 'هاتان',\n 'هاته',\n 'هاتي',\n 'هاتين',\n 'هاك',\n 'هاهنا',\n 'هذا',\n 'هذان',\n 'هذه',\n 'هذي',\n 'هذين',\n 'هكذا',\n 'هل',\n 'هلا',\n 'هم',\n 'هما',\n 'هن',\n 'هنا',\n 'هناك',\n 'هنالك',\n 'هو',\n 'هؤلاء',\n 'هي',\n 'هيا',\n 'هيت',\n 'هيهات',\n 'والذي',\n 'والذين',\n 'وإذ',\n 'وإذا',\n 'وإن',\n 'ولا',\n 'ولكن',\n 'ولو',\n 'وما',\n 'ومن',\n 'وهو',\n 'يا',\n 'أبٌ',\n 'أخٌ',\n 'حمٌ',\n 'فو',\n 'أنتِ',\n 'يناير',\n 'فبراير',\n 'مارس',\n 'أبريل',\n 'مايو',\n 'يونيو',\n 'يوليو',\n 'أغسطس',\n 'سبتمبر',\n 'أكتوبر',\n 'نوفمبر',\n 'ديسمبر',\n 'جانفي',\n 'فيفري',\n 'مارس',\n 'أفريل',\n 'ماي',\n 'جوان',\n 'جويلية',\n 'أوت',\n 'كانون',\n 'شباط',\n 'آذار',\n 'نيسان',\n 'أيار',\n 'حزيران',\n 'تموز',\n 'آب',\n 'أيلول',\n 'تشرين',\n 'دولار',\n 'دينار',\n 'ريال',\n 'درهم',\n 'ليرة',\n 'جنيه',\n 'قرش',\n 'مليم',\n 'فلس',\n 'هللة',\n 'سنتيم',\n 'يورو',\n 'ين',\n 'يوان',\n 'شيكل',\n 'واحد',\n 'اثنان',\n 'ثلاثة',\n 'أربعة',\n 'خمسة',\n 'ستة',\n 'سبعة',\n 'ثمانية',\n 'تسعة',\n 'عشرة',\n 'أحد',\n 'اثنا',\n 'اثني',\n 'إحدى',\n 'ثلاث',\n 'أربع',\n 'خمس',\n 'ست',\n 'سبع',\n 'ثماني',\n 'تسع',\n 'عشر',\n 'ثمان',\n 'سبت',\n 'أحد',\n 'اثنين',\n 'ثلاثاء',\n 'أربعاء',\n 'خميس',\n 'جمعة',\n 'أول',\n 'ثان',\n 'ثاني',\n 'ثالث',\n 'رابع',\n 'خامس',\n 'سادس',\n 'سابع',\n 'ثامن',\n 'تاسع',\n 'عاشر',\n 'حادي',\n 'أ',\n 'ب',\n 'ت',\n 'ث',\n 'ج',\n 'ح',\n 'خ',\n 'د',\n 'ذ',\n 'ر',\n 'ز',\n 'س',\n 'ش',\n 'ص',\n 'ض',\n 'ط',\n 'ظ',\n 'ع',\n 'غ',\n 'ف',\n 'ق',\n 'ك',\n 'ل',\n 'م',\n 'ن',\n 'ه',\n 'و',\n 'ي',\n 'ء',\n 'ى',\n 'آ',\n 'ؤ',\n 'ئ',\n 'أ',\n 'ة',\n 'ألف',\n 'باء',\n 'تاء',\n 'ثاء',\n 'جيم',\n 'حاء',\n 'خاء',\n 'دال',\n 'ذال',\n 'راء',\n 'زاي',\n 'سين',\n 'شين',\n 'صاد',\n 'ضاد',\n 'طاء',\n 'ظاء',\n 'عين',\n 'غين',\n 'فاء',\n 'قاف',\n 'كاف',\n 'لام',\n 'ميم',\n 'نون',\n 'هاء',\n 'واو',\n 'ياء',\n 'همزة',\n 'ي',\n 'نا',\n 'ك',\n 'كن',\n 'ه',\n 'إياه',\n 'إياها',\n 'إياهما',\n 'إياهم',\n 'إياهن',\n 'إياك',\n 'إياكما',\n 'إياكم',\n 'إياك',\n 'إياكن',\n 'إياي',\n 'إيانا',\n 'أولالك',\n 'تانِ',\n 'تانِك',\n 'تِه',\n 'تِي',\n 'تَيْنِ',\n 'ثمّ',\n 'ثمّة',\n 'ذانِ',\n 'ذِه',\n 'ذِي',\n 'ذَيْنِ',\n 'هَؤلاء',\n 'هَاتانِ',\n 'هَاتِه',\n 'هَاتِي',\n 'هَاتَيْنِ',\n 'هَذا',\n 'هَذانِ',\n 'هَذِه',\n 'هَذِي',\n 'هَذَيْنِ',\n 'الألى',\n 'الألاء',\n 'أل',\n 'أنّى',\n 'أيّ',\n 'ّأيّان',\n 'أنّى',\n 'أيّ',\n 'ّأيّان',\n 'ذيت',\n 'كأيّ',\n 'كأيّن',\n 'بضع',\n 'فلان',\n 'وا',\n 'آمينَ',\n 'آهِ',\n 'آهٍ',\n 'آهاً',\n 'أُفٍّ',\n 'أُفٍّ',\n 'أفٍّ',\n 'أمامك',\n 'أمامكَ',\n 'أوّهْ',\n 'إلَيْكَ',\n 'إلَيْكَ',\n 'إليكَ',\n 'إليكنّ',\n 'إيهٍ',\n 'بخٍ',\n 'بسّ',\n 'بَسْ',\n 'بطآن',\n 'بَلْهَ',\n 'حاي',\n 'حَذارِ',\n 'حيَّ',\n 'حيَّ',\n 'دونك',\n 'رويدك',\n 'سرعان',\n 'شتانَ',\n 'شَتَّانَ',\n 'صهْ',\n 'صهٍ',\n 'طاق',\n 'طَق',\n 'عَدَسْ',\n 'كِخ',\n 'مكانَك',\n 'مكانَك',\n 'مكانَك',\n 'مكانكم',\n 'مكانكما',\n 'مكانكنّ',\n 'نَخْ',\n 'هاكَ',\n 'هَجْ',\n 'هلم',\n 'هيّا',\n 'هَيْهات',\n 'وا',\n 'واهاً',\n 'وراءَك',\n 'وُشْكَانَ',\n 'وَيْ',\n 'يفعلان',\n 'تفعلان',\n 'يفعلون',\n 'تفعلون',\n 'تفعلين',\n 'اتخذ',\n 'ألفى',\n 'تخذ',\n 'ترك',\n 'تعلَّم',\n 'جعل',\n 'حجا',\n 'حبيب',\n 'خال',\n 'حسب',\n 'خال',\n 'درى',\n 'رأى',\n 'زعم',\n 'صبر',\n 'ظنَّ',\n 'عدَّ',\n 'علم',\n 'غادر',\n 'ذهب',\n 'وجد',\n 'ورد',\n 'وهب',\n 'أسكن',\n 'أطعم',\n 'أعطى',\n 'رزق',\n 'زود',\n 'سقى',\n 'كسا',\n 'أخبر',\n 'أرى',\n 'أعلم',\n 'أنبأ',\n 'حدَث',\n 'خبَّر',\n 'نبَّا',\n 'أفعل به',\n 'ما أفعله',\n 'بئس',\n 'ساء',\n 'طالما',\n 'قلما',\n 'لات',\n 'لكنَّ',\n 'ءَ',\n 'أجل',\n 'إذاً',\n 'أمّا',\n 'إمّا',\n 'إنَّ',\n 'أنًّ',\n 'أى',\n 'إى',\n 'أيا',\n 'ب',\n 'ثمَّ',\n 'جلل',\n 'جير',\n 'رُبَّ',\n 'س',\n 'علًّ',\n 'ف',\n 'كأنّ',\n 'كلَّا',\n 'كى',\n 'ل',\n 'لات',\n 'لعلَّ',\n 'لكنَّ',\n 'لكنَّ',\n 'م',\n 'نَّ',\n 'هلّا',\n 'وا',\n 'أل',\n 'إلّا',\n 'ت',\n 'ك',\n 'لمّا',\n 'ن',\n 'ه',\n 'و',\n 'ا',\n 'ي',\n 'تجاه',\n 'تلقاء',\n 'جميع',\n 'حسب',\n 'سبحان',\n 'شبه',\n 'لعمر',\n 'مثل',\n 'معاذ',\n 'أبو',\n 'أخو',\n 'حمو',\n 'فو',\n 'مئة',\n 'مئتان',\n 'ثلاثمئة',\n 'أربعمئة',\n 'خمسمئة',\n 'ستمئة',\n 'سبعمئة',\n 'ثمنمئة',\n 'تسعمئة',\n 'مائة',\n 'ثلاثمائة',\n 'أربعمائة',\n 'خمسمائة',\n 'ستمائة',\n 'سبعمائة',\n 'ثمانمئة',\n 'تسعمائة',\n 'عشرون',\n 'ثلاثون',\n 'اربعون',\n 'خمسون',\n 'ستون',\n 'سبعون',\n 'ثمانون',\n 'تسعون',\n 'عشرين',\n 'ثلاثين',\n 'اربعين',\n 'خمسين',\n 'ستين',\n 'سبعين',\n 'ثمانين',\n 'تسعين',\n 'بضع',\n 'نيف',\n 'أجمع',\n 'جميع',\n 'عامة',\n 'عين',\n 'نفس',\n 'لا سيما',\n 'أصلا',\n 'أهلا',\n 'أيضا',\n 'بؤسا',\n 'بعدا',\n 'بغتة',\n 'تعسا',\n 'حقا',\n 'حمدا',\n 'خلافا',\n 'خاصة',\n 'دواليك',\n 'سحقا',\n 'سرا',\n 'سمعا',\n 'صبرا',\n 'صدقا',\n 'صراحة',\n 'طرا',\n 'عجبا',\n 'عيانا',\n 'غالبا',\n 'فرادى',\n 'فضلا',\n 'قاطبة',\n 'كثيرا',\n 'لبيك',\n 'معاذ',\n 'أبدا',\n 'إزاء',\n 'أصلا',\n 'الآن',\n 'أمد',\n 'أمس',\n 'آنفا',\n 'آناء',\n 'أنّى',\n 'أول',\n 'أيّان',\n 'تارة',\n 'ثمّ',\n 'ثمّة',\n 'حقا',\n 'صباح',\n 'مساء',\n 'ضحوة',\n 'عوض',\n 'غدا',\n 'غداة',\n 'قطّ',\n 'كلّما',\n 'لدن',\n 'لمّا',\n 'مرّة',\n 'قبل',\n 'خلف',\n 'أمام',\n 'فوق',\n 'تحت',\n 'يمين',\n 'شمال',\n 'ارتدّ',\n 'استحال',\n 'أصبح',\n 'أضحى',\n 'آض',\n 'أمسى',\n 'انقلب',\n 'بات',\n 'تبدّل',\n 'تحوّل',\n 'حار',\n 'رجع',\n 'راح',\n 'صار',\n 'ظلّ',\n 'عاد',\n 'غدا',\n 'كان',\n 'ما انفك',\n 'ما برح',\n 'مادام',\n 'مازال',\n 'مافتئ',\n 'ابتدأ',\n 'أخذ',\n 'اخلولق',\n 'أقبل',\n 'انبرى',\n 'أنشأ',\n 'أوشك',\n 'جعل',\n 'حرى',\n 'شرع',\n 'طفق',\n 'علق',\n 'قام',\n 'كرب',\n 'كاد',\n 'هبّ']"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"arabic\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:08:54.381209Z",
     "start_time": "2023-06-25T00:08:54.373139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:10:04.642536Z",
     "start_time": "2023-06-25T00:10:04.630174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "'This is a paragraph. It should split at the end of sentence marker, such as a period. It can tell that the period in Mr. Daniel is not an end. Run it!, Hey How are you doing'"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:10:10.491430Z",
     "start_time": "2023-06-25T00:10:10.487030Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "['This',\n 'is',\n 'a',\n 'paragraph.',\n 'It',\n 'should',\n 'split',\n 'at',\n 'the',\n 'end',\n 'of',\n 'sentence',\n 'marker,',\n 'such',\n 'as',\n 'a',\n 'period.',\n 'It',\n 'can',\n 'tell',\n 'that',\n 'the',\n 'period',\n 'in',\n 'Mr.',\n 'Daniel',\n 'is',\n 'not',\n 'an',\n 'end.',\n 'Run',\n 'it!,',\n 'Hey',\n 'How',\n 'are',\n 'you',\n 'doing']"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\"\\s\",string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:13:11.953132Z",
     "start_time": "2023-06-25T00:13:11.949417Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "'This is a paragraph. It should split at the end of sentence marker such as a period. It can tell that the period in Mr. Daniel is not an end. Run it! Hey How are you doing'"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\",\",\"\",string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:13:55.220618Z",
     "start_time": "2023-06-25T00:13:55.215764Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "['the', 'the']"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"the\",string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:14:27.943207Z",
     "start_time": "2023-06-25T00:14:27.939385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "<re.Match object; span=(40, 43), match='the'>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = re.search(\"the\",string)\n",
    "g"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:15:19.401166Z",
     "start_time": "2023-06-25T00:15:19.397900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "'This is a paragraph. It should split at the end of sentence marker, such as a period. It can tell that the period in Mr. Daniel is not an end. Run it!, Hey How are you doing'"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:16:54.811751Z",
     "start_time": "2023-06-25T00:16:54.807982Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "string1 = \"Box A has 4 red and 6 white balls, while Box B has 3 red and 5 blue balls.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:20:22.755596Z",
     "start_time": "2023-06-25T00:20:22.752903Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "'Box A has 4 red and 6 white balls, while Box B has 3 red and 5 blue balls.'"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:20:25.670110Z",
     "start_time": "2023-06-25T00:20:25.665822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "string = 'This is a paragraph. It should split at the end of sentence marker, such as a period. It can tell that the period in Mr. Daniel is not an end. Run it!, Hey How are you doing'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:20:26.640461Z",
     "start_time": "2023-06-25T00:20:26.637752Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "'Box A has  red and  white balls, while Box B has  red and  blue balls.'"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = re.sub(\"\\d+\",\"\",string1)\n",
    "h"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:46:33.156637Z",
     "start_time": "2023-06-25T00:46:33.153787Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "'Box A has red and white balls, while Box B has red and blue balls.'"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"  \",\" \",h)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:23:45.118520Z",
     "start_time": "2023-06-25T00:23:45.115374Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\r\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m636.8/636.8 kB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: nltk>=3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textblob) (3.8.1)\r\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.1->textblob) (8.1.3)\r\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.1->textblob) (1.2.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.1->textblob) (2023.5.5)\r\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.1->textblob) (4.65.0)\r\n",
      "Installing collected packages: textblob\r\n",
      "Successfully installed textblob-0.17.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:30:30.130996Z",
     "start_time": "2023-06-25T00:30:28.585129Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:30:49.845787Z",
     "start_time": "2023-06-25T00:30:49.834329Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "[('This', 'DT'),\n ('is', 'VBZ'),\n ('a', 'DT'),\n ('paragraph', 'NN'),\n ('It', 'PRP'),\n ('should', 'MD'),\n ('split', 'VB'),\n ('at', 'IN'),\n ('the', 'DT'),\n ('end', 'NN'),\n ('of', 'IN'),\n ('sentence', 'NN'),\n ('marker', 'NN'),\n ('such', 'JJ'),\n ('as', 'IN'),\n ('a', 'DT'),\n ('period', 'NN'),\n ('It', 'PRP'),\n ('can', 'MD'),\n ('tell', 'VB'),\n ('that', 'IN'),\n ('the', 'DT'),\n ('period', 'NN'),\n ('in', 'IN'),\n ('Mr.', 'NNP'),\n ('Daniel', 'NNP'),\n ('is', 'VBZ'),\n ('not', 'RB'),\n ('an', 'DT'),\n ('end', 'NN'),\n ('Run', 'VB'),\n ('it', 'PRP'),\n ('Hey', 'NNP'),\n ('How', 'NNP'),\n ('are', 'VBP'),\n ('you', 'PRP'),\n ('doing', 'VBG')]"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = TextBlob(string)\n",
    "x.tags"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:31:40.175382Z",
     "start_time": "2023-06-25T00:31:40.127937Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:45:23.823532Z",
     "start_time": "2023-06-25T00:45:23.812851Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "['arabic',\n 'azerbaijani',\n 'basque',\n 'bengali',\n 'catalan',\n 'chinese',\n 'danish',\n 'dutch',\n 'english',\n 'finnish',\n 'french',\n 'german',\n 'greek',\n 'hebrew',\n 'hinglish',\n 'hungarian',\n 'indonesian',\n 'italian',\n 'kazakh',\n 'nepali',\n 'norwegian',\n 'portuguese',\n 'romanian',\n 'russian',\n 'slovene',\n 'spanish',\n 'swedish',\n 'tajik',\n 'turkish']"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:45:41.505633Z",
     "start_time": "2023-06-25T00:45:41.503017Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:47:46.682561Z",
     "start_time": "2023-06-25T00:47:46.665428Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "data": {
      "text/plain": "Synset('hello.n.01')"
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = wordnet.synsets('hello')[0]\n",
    "s"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:49:50.266923Z",
     "start_time": "2023-06-25T00:49:50.261387Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "'n'"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.pos()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:49:20.079953Z",
     "start_time": "2023-06-25T00:49:20.068534Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import bigrams\n",
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:53:29.079143Z",
     "start_time": "2023-06-25T00:53:29.072711Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "['This',\n 'is',\n 'a',\n 'paragraph',\n '.',\n 'It',\n 'should',\n 'split',\n 'at',\n 'the',\n 'end',\n 'of',\n 'sentence',\n 'marker',\n ',',\n 'such',\n 'as',\n 'a',\n 'period',\n '.',\n 'It',\n 'can',\n 'tell',\n 'that',\n 'the',\n 'period',\n 'in',\n 'Mr.',\n 'Daniel',\n 'is',\n 'not',\n 'an',\n 'end',\n '.',\n 'Run',\n 'it',\n '!',\n ',',\n 'Hey',\n 'How',\n 'are',\n 'you',\n 'doing']"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = word_tokenize(string)\n",
    "g"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:53:29.338061Z",
     "start_time": "2023-06-25T00:53:29.334709Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[197], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbigrams\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(h)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "h = list(bigrams(g))\n",
    "print(h)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:53:29.707215Z",
     "start_time": "2023-06-25T00:53:29.705567Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[198], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData Science is a totally new kind of learning experience.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m Tokens \u001B[38;5;241m=\u001B[39m nltk\u001B[38;5;241m.\u001B[39mword_tokenize(text)\n\u001B[0;32m----> 3\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnltk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbigrams\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTokens\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m output\n",
      "\u001B[0;31mTypeError\u001B[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "text = \"Data Science is a totally new kind of learning experience.\"\n",
    "Tokens = nltk.word_tokenize(text)\n",
    "output = list(nltk.bigrams(Tokens))\n",
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:53:30.074476Z",
     "start_time": "2023-06-25T00:53:30.072200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T00:58:56.969215Z",
     "start_time": "2023-06-25T00:58:56.962086Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "syn = wordnet.synsets(\"idiot\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T01:01:48.465341Z",
     "start_time": "2023-06-25T01:01:48.459149Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "data": {
      "text/plain": "[Synset('idiot.n.01')]"
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T01:01:48.767474Z",
     "start_time": "2023-06-25T01:01:48.760679Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n"
     ]
    }
   ],
   "source": [
    "for i in syn:\n",
    "\tprint(i.pos())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T01:01:51.946476Z",
     "start_time": "2023-06-25T01:01:51.940003Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[282], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43msyn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "syn.name()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T01:01:52.956308Z",
     "start_time": "2023-06-25T01:01:52.952970Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition of Synset('idiot.n.01') : a person of subnormal intelligence\n"
     ]
    }
   ],
   "source": [
    "for i in syn:\n",
    "    print(\"Definition of {} : {}\".format(i,i.definition()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T01:01:56.470048Z",
     "start_time": "2023-06-25T01:01:56.455097Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of Synset('idiot.n.01') : []\n"
     ]
    }
   ],
   "source": [
    "for i in syn:\n",
    "    print(\"Example of {} : {}\".format(i,i.examples()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T01:01:59.165966Z",
     "start_time": "2023-06-25T01:01:59.156737Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [
    {
     "data": {
      "text/plain": "[('This', 'DT'),\n ('is', 'VBZ'),\n ('a', 'DT'),\n ('paragraph', 'NN'),\n ('It', 'PRP'),\n ('should', 'MD'),\n ('split', 'VB'),\n ('at', 'IN'),\n ('the', 'DT'),\n ('end', 'NN'),\n ('of', 'IN'),\n ('sentence', 'NN'),\n ('marker', 'NN'),\n ('such', 'JJ'),\n ('as', 'IN'),\n ('a', 'DT'),\n ('period', 'NN'),\n ('It', 'PRP'),\n ('can', 'MD'),\n ('tell', 'VB'),\n ('that', 'IN'),\n ('the', 'DT'),\n ('period', 'NN'),\n ('in', 'IN'),\n ('Mr.', 'NNP'),\n ('Daniel', 'NNP'),\n ('is', 'VBZ'),\n ('not', 'RB'),\n ('an', 'DT'),\n ('end', 'NN'),\n ('Run', 'VB'),\n ('it', 'PRP'),\n ('Hey', 'NNP'),\n ('How', 'NNP'),\n ('are', 'VBP'),\n ('you', 'PRP'),\n ('doing', 'VBG')]"
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = TextBlob(string)\n",
    "te.tags"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T01:16:00.953253Z",
     "start_time": "2023-06-25T01:16:00.947782Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.sentiment.polarity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T01:17:04.791961Z",
     "start_time": "2023-06-25T01:17:04.787768Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
